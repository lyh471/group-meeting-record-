## 自动求导：

### 原理：

**自动求导的基本原理：**对要求导的模型生成对应的计算图，然后将计算操作的function记录在Tensor的grad_fn中。对根节点进行backward函数（反向传播）操作，即可从当前根节点自动进行反向传播与梯度计算，从而得到每一个叶子节点的梯度，这些梯度计算遵循链式求导法则。

**前向传播：**按顺序（从输入层到输出层）计算和存储神经网络中每层的结果

**反向传播：**计算神经网络参数梯度的方法，简而言之，该方法根据微积分中的链式法则，按相反的顺序从输出层到输入层遍历网络

- 在训练深度学习模型时，前向传播和反向传播相互依赖
- 训练比预测需要更多的内存
- 前向传播在神经网络定义的计算图中按顺序计算和存储中间变量，它的顺序是从输入层到输出层
- 反向传播按相反的顺序（从输出层到输入层）计算和存储神经网络的中间变量和参数梯度

总之，==在训练神经网络时，前向传播和反向传播互相依赖。对于前向传播，我们沿着依赖的方向遍历计算图并计算其路径上的所有变量，然后将这些用于反向传播，其计算顺序与计算图相反==

#### 计算图：

设模型*z = 2x + xy*，生成如下计算图
$$
z = 2x + xy
$$
<img src="C:\Users\lyh471\AppData\Roaming\Typora\typora-user-images\image-20220602162613419.png" alt="image-20220602162613419" style="zoom:33%;" />

其中
$$
u = 2x \\ v = xy \\ z = u+v
$$
u，v是我自己定义的中间过程， *z = 2x + xy*的图中应该不会出现。

x、y是用户自己创建，在图中可以理解为叶节点，u、v是经过乘法产生的中间节点，然后相加最终输出z，并作为根节点。

记住这个图，下面用代码来说说自动求导怎么用。心里有这个图，代码实现的过程或许会很清楚

### 一个比书上还简单的例子：

书上举的是对一个4维向量**x**求导，我在上面画了一个 *z = 2x + xy* 的计算图，那么就求一下z对x和y的偏导吧

初始值设x = 3，y = 6

*演算一下，关于x的偏导应该为2+y = 8，关于y的偏导应该为x = 3*

以8和3为目标！！

在设立初值时还需要将requires_grad设置为True

requires_grad是啥？往下看😸

#### requires_grad

requires_grad可以理解为一个标志位，当requires_grad为True时可以对其求导，内存会开辟一个存储空间来存储导数。

初始时requires_grad默认为False，这样就能保证每生成一个参数时都不用在为导数考虑内存。

用不到的就不分，不需要的还要分配内存，内存不就被浪费完了吗，所以初始默认为False，对需要求导的变量时在去设置为True。

书上有两个方法可以设置该标志位，见代码注释

~~~py
#为x，y设初值
import torch

x = torch.tensor(3.,requires_grad = True) #在生成张量时直接将标志位设置为True

y = torch.tensor(6.)
y.requires_grad_(True) #调用标志位设置函数将标志设置为True
~~~

这两种方法都可以，还有一点需要注意的是，该标志位是具有传递性的

即x和y设置了为True

*u = 2x 、v = xy* ，u和v的requires_grad也为True

#### grad_fn

在原理中提到：对Tensor的计算操作会生成对应的计算图，然后将计算操作的function记录在Tensor的grad_fn

令*u = 2x 、v = xy*

~~~py
u = 2*x
v = x*y

u,v

(tensor(6., grad_fn=<MulBackward0>), tensor(18., grad_fn=<MulBackward0>))
#grad_fn记录该变量生成经历了什么操作,u，v的生成由mul得到（乘法）
~~~

==u的定义相当于生成了一个最简单的图，u为顶点它有两个起点分别为2和x，操作为乘法==，就是u在定义的时候，pytorch就会自动生成一张这样的图，应该只有当requires_grad为True时才会产生？

<img src="C:\Users\lyh471\AppData\Roaming\Typora\typora-user-images\image-20220602185243749.png" alt="image-20220602185243749" style="zoom:33%;" />

它的好处是在进行反向传播时底层逻辑可以根据grad_fn所保存的状态来应用对应的求导法则

~~~PY
z = u+v

z

tensor(24., grad_fn=<AddBackward0>)
#z的生成由add得到（加法）
~~~

为了体现grad_fn的作用我上面做了一步u和v的分解，若 *z = 2x + xy* 直接产生grad_fn保存的什么状态？

~~~py
z = 2*x + x*y

z

tensor(24., grad_fn=<AddBackward0>) #还是加法，理解为记录计算图中最后一部分的计算操作
~~~

#### backward()

在设置了求导标志位和建立完模型，模型生成后就会自动生成了计算图，这样就可以利用backward()函数对所要求的变量自动求导

根据模型的整个计算图反向传播跟踪，只要requires_grad为True，就填充这个参数对应的偏导数

调用这个函数后，z对于x，y的偏导数已经求出来了，直接x.grad和y.grad就可以显示

~~~py
z.backward()
x.grad, y.grad

(tensor(8.), tensor(3.))
~~~

**目标达成！**🐲

因为requires_grad具有传递性的，u和v调用backward()，x.grad和y.grad表示的就是u或v对于x，y的偏导数了

以v为例吧，*v = xy*

v对x求偏导是y，对y求偏导是x。所以答案是6和3！

⚠️注意：再次求导时需要将上次求导结果清0，调用grad.zero_()即可清0。

⚠️注意：好像没那么简单，因为v在调用backward()时出错啦😿错误如下所示

~~~
Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.
~~~

这个错误的原因，弄懂原理啦！

⚠️每次 backward() 时，会默认把整个计算图free掉。一般情况下是每次迭代，只需一次 forward() 和一次 backward() ,前向运算forward() 和反向传播backward()是成对存在的，一般一次backward()也是够用的。

 但是不排除，由于自定义loss等的复杂性，需要一次forward()，多个不同loss的backward()来累积同一个网络的grad,来更新参数。

于是，若在当前backward()后，不执行forward() 而是执行另一个backward()，需要在当前backward()时，指定保留计算图，backward(retain_graph)。

所以z在调用backward()时将retain_graph =true就可以了

~~~py
z.backward(retain_graph=True)

x.grad.zero_()
y.grad.zero_()

v.backward()
x.grad, y.grad

(tensor(6.), tensor(3.))
~~~

**目标再次达成！**🐲

#### 小结：

1. 获得模型（设模型为z = f(x,y)），建立模型后会自动生成计算图，模型的计算操作得到会保存在grad_fn中
2. 对z求x或y的偏导，将对应变量的requires_grad设置为True
3. z.backward()，z调用反向传播函数，x或y的导数自动求出
4. x.grad/y.grad显示导数

### 非标量变量的反向传播：

一般建立的模型输出结果是标量，因为标量可以表示损失，表示一个实际的意义。

但当输出不再是标量而是一个向量时，向量y关于向量x的导数就是一个矩阵

*但是书上寥寥几笔，我属实没看明白，还是自己琢磨着弄明白吧*😿

琢磨完了，粗浅的介绍一下，底层原理弄明白个大概。

首先可以粗浅的认为backward()就是在根据计算图计算tensor的“梯度”，但是这个“梯度”只有在输出是标量时才是真正意义上的梯度。

#### gradient

当输出是一个向量时求梯度是需要设置gradient参数的，这个参数在实际使用的过程中，是一个与用.backward()的张量维度一致的张量，且该张量的元素值为1。

原因❓

**向量的求导的结果是雅可比矩阵，但实际上backward()求出的只是雅可比矩阵中每一个元素的梯度值（标量），所以需要将这些标量转换成向量，转换的底层逻辑是将这些值与求导向量大小一致的向量进行点乘运算，这样输出结果与所求导向量维度一致，而输出的向量的分量数值是雅可比矩阵行向量之和，为了保证数值的正确性，这个点乘的向量各元素数值应为1**，==这个进行结果转换的向量，就是需要设置的gradient参数。==

为什么所求结果是**雅可比矩阵行向量之和**？因为**实际应用的目的**往往不是计算微分矩阵，而是单独计算批量中每个样本的偏导数之和，并且底层逻辑的转换所得到的结果也是这种形式。

#### 向量求导：

举个向量求导的例子

~~~py
a = torch.tensor([[2.,4.]],requires_grad = True)
b = torch.zeros(1,2)
b[0,0] = a[0,0]**2 + a[0,1]
b[0,1] = a[0,1]**3 + a[0,0]
c = 2*b
~~~

向量c表达式可概括为
$$
c = [[2a_0^2+2a_1, 2a_1^3+2a_0]]
$$
雅可比矩阵结果应该为[ [ 8 , 2 ], [ 2 , 96] ]

所以最终结果关于a的每个分量的偏导数之和应为[10 , 98]

~~~py
c.backward(torch.ones(1,2))#设置gradient参数
a.grad

tensor([[10., 98.]])
~~~

### 分离计算：

有时，我们希望将某些计算移动到记录的计算图之外。

还是以 *z = 2x + xy* 为例，计算z关于x的梯度，但由于某种原因，希望将 *2x* 看作常数，即当x = 3，y = 6时，*2x* 看作为常数时，求z关于x的偏导数为y = 6。（就是上面v = xy关于x的偏导数）

可以使用detach方法将 *2x* 从计算图分离出来。

~~~PY
import torch
x = torch.tensor(3.,requires_grad = True) 
y = torch.tensor(6.)
y.requires_grad_(True) 

u = 2*x
u_ = u.detach() #调用detach方法将u从计算图中分离，分离后状态下赋值给u_

z = u_+ x*y #此时z的计算图中u_看作常数，不参与求导

z.backward()

x.grad

tensor(6.)
~~~

**目标叒次达成！**🐲



## 线性回归从零开始实现

上个星期学会了线性回归的关键思想，今天通过代码手动实现线性回归

线性回归解决的问题，找到一个合适的线性模型，可以对数据集的输入特征和结果进行映射，并且映射的误差要尽可能的小，这样在对一个新的输入特征时，通过自定义的线性模型输出得到误差不会太大的预测结果

深度学习框架可以自动的实现**数据流水线、模型、损失函数和小批量随机梯度下降优化器**，等这些功能，但从零开始一步一步手动实现对我领悟的将更加透彻😸

下面结合书中的代码，尽量看懂每一行代码并添加注释。手动来还原一下建立一个符合条件的线性回归模型

首先调用了一些包

~~~py
%matplotlib inline #内置数据可视化，暂时不会用，有机会一定学习一下
import random #产生随机数的包
import torch #导入pytorch框架
from d2l import torch as d2l #从d2l包中导入torch并改名叫做d2l
#这里应该是d2l中的torch有自定义的特别函数,但是和基本的torch区分,又改了名字
~~~

### 生成数据集：

#### 原理：

从零开始自然是什么都没有的，所以需要自己建立一个训练集

怎么生成呢，很简单，建立一个线性模型，然后在这个模型的基础上加一些噪声干扰数据的输出，保证输出的结果不是线性分布。随机输入然后得到输出，就能得到一个数据集啦，最后确定权重和偏置时应该和这个线性模型的权重和偏置是差不多的，这样也能确认自己建立的模型是否准确。

书中生成的是一个包含1000个样本的数据集， 且每个样本包含从标准正态分布中采样的2个特征。 合成数据集是一个矩阵𝐗∈ℝ^1000×2^，一个1000x2的矩阵

这里书上选用线性模型的参数权重𝐰=[2,−3.4]^⊤^，偏置为𝑏=4.2，和一个噪声项𝜖，==𝜖视为模型预测和标签时的潜在观测误差。 在这里认为标准假设成立，即𝜖服从均值为0的正态分布。 为了简化问题，将标准差设为0.01==

😿上面高光是书上的原话，我完全没看懂，不过意思应该是这个噪声项𝜖随机产生满足均值为0的正态分布，且随机产生的值的标准差为0.01
$$
𝐲=𝐗𝐰+𝑏+𝜖.
$$
即随机生成**X**，代入上述模型输出**y**，得到1000个这样的数据就是我们需要生成的训练集，下面用代码实现

#### 生成数据集函数：

~~~PY
#建立生成数据集函数
def synthetic_data(w, b, num_examples):  #w为权重,b为偏置,num_examples为生成数据集个数
    """生成y=Xw+b+噪声"""
    X = torch.normal(0, 1, (num_examples, len(w))) 
    #随机生成一个形状为(num_examples, len(w))的张量,本例为(1000,2)的张量
    #且数值满足均值为0标准差为1的正态分布
    #数据集的特征值
    
    
    y = torch.matmul(X, w) + b
    #符合该线性模型的输出
    #数据集的标签值
    
    y += torch.normal(0, 0.01, y.shape)
    #增加噪声项，改变线性结构,使数据接近线性分布,但不是线性分布
    
    return X, y.reshape((-1, 1))
	#返回数据集(特征值，标签值)
    #返回的标签值是行向量，无法与特征对应，将标签值行向量重塑为列向量
~~~

🛂*注释解释的那么明显，这个生成数据集的函数完全能看懂啦！*

#### torch.normal()

上面代码中用到了torch这个函数，简略解释一下，以后遇到没见过的函数都这样提一嘴，然后学会怎么用，积少成多吗😸

调用该返回一个张量，张量的数值从给定参数means（均值）,std（标准差）的离散正态分布中抽取随机数。

- **means** -- 均值
- **std** -- 标准差
- **size** -- 输出张量的大小

#### 应用：

有了生成数据集函数，就要调用该函数啦

~~~py
true_w = torch.tensor([2, -3.4])
true_b = 4.2
#模型参数

features, labels = synthetic_data(true_w, true_b, 1000) 
#传参，调用生成数据集函数，返回数据赋值给特征变量和标签变量
#features中的每一行都包含一个二维数据样本， labels中的每一行都包含一维标签值（一个标量）
~~~

这样就有数据集啦，书上下面的代码好像是将这些数据可视化，说实话我没有看明白并且不想深究🙉，偷个懒这里先跳过啦，有空一定学学如何将数据在 *jupyter notebook* 上可视化

### 读取数据集：

在随机梯度那一节提到，每次更新模型都要遍历整个数据集那这个代价真是太大了，所以使用它的变体

每次计算更新读取数据集的时候只随机抽取一小批样本， 还记得这种方法吗？这种方法是**小批量随机梯度下降**

所以需要写一个读取数据集的函数，它应满足从输入的特征矩阵和标签向量中，随机生成大小为batch_size的小批量数据样本，每个小批量包含一组特征和标签。

书上已经帮忙写好啦，直接分析这个函数怎么实现的

#### 随机生成小批量数据集函数：

~~~py
#根据输入特征和标签,构建随机生成小批量数据集函数
#参数batch_size为批量大小,features输入特征,labels标签向量
def data_iter(batch_size, features, labels):  

    num_examples = len(features) #这里的len返回的是张量0轴的长度！！！！！差点把我绕晕了
    
    indices = list(range(num_examples))
    #indices是一个[0,1000)的随机列表
    #这些样本是随机读取的，没有特定的顺序
    
    random.shuffle(indices)
    #将列表indices中的元素打乱顺序,该方法不会生成新的列表,只是将原列表的次序打乱
    #该方法只能适用于list,并不适用于tensor
    
    
    
    #下面是代码核心,读明白花费了不少力气
    for i in range(0, num_examples, batch_size):
    #从0开始,到num_examples结束,每次步长为batch_size大小    
     
        #生成一个批量大小长度的随机索引,保存在batch_indices中
        #batch_indices中存储的是随机索引长度为batch_size
        #batch_indices虽是张量,但我感觉更像列表
        batch_indices = torch.tensor(
            indices[i: min(i + batch_size, num_examples)])
        	#每次拿取长度为batch_size随机索引出来,当最后一次拿取时超出长度,取最小值全拿出来
            
        yield features[batch_indices], labels[batch_indices]
        #关键字yield,可以理解为return,但返回完函数并不会结束,它会记录函数执行的位置
        #并在返回后继续执行,直到函数结束
~~~

还有地方不明白，返回的**features[batch_indices], labels[batch_indices]** 是什么东西？

在看一段代码

~~~py
import torch

x = torch.tensor([3,2])
y = torch.tensor([6,68,98,328])

y[x]

tensor([328,  98])
#即返回的是tensor([y[3],y[2]])
~~~

==所以**features[batch_indices]**是len为batch_size，与原特征数据集相比行序随机的张量==

*这个函数实现的真是妙啊！*😻

#### 应用：

有了随机生成小批量数据集函数，直接赋值使用不就是读取了吗

~~~py
batch_size = 5 #书上生成了10个，我生成5个看看怎么用的就行

for X, y in data_iter(batch_size, features, labels): #调用函数
    print(X, '\n', y)
    break #生成batch_size大小的数据集就ok了,不用再继续生成下一个batch_size大小的数据集
    
tensor([[ 0.8281, -0.1118],
        [ 2.2422, -0.5765],
        [ 0.5290, -0.1211],
        [ 1.2218,  0.0875],
        [ 1.0090,  1.3193]]) 
 tensor([[ 6.2326],
        [10.6560],
        [ 5.6716],
        [ 6.3503],
        [ 1.7340]])
~~~

如果不break，会连续地获得不同的小批量数据集，直至遍历完整个数据集。 

上面实现的迭代对于教学来说很好，但它的执行效率很低，可能会在实际问题上陷入麻烦。 例如，它要求我们将所有数据加载到内存中，并执行大量的随机内存访问。

 在深度学习框架中实现的内置迭代器效率要高得多， 它可以处理存储在文件中的数据和数据流提供的数据。

*书上原话，确实这个函数对于教学让我对小批量的迭代印象深刻，虽然有效率更好的内置的小批量数据生成函数，但自己实现一下更能清楚原理，并明白了这个小批量随机程度的含金量*😸

### 初始化模型参数：

ok，训练集已经有了，建立一个线性模型首先需要参数。

这个参数的初值书上也是随机确定，并不是自己指定。

确实有一定的道理，与其随机猜一个数不如交给老天爷决定😼

书上通过从均值为0、标准差为0.01的正态分布中采样随机数来初始化权重， 并将偏置初始化为0。

~~~py
w = torch.normal(0, 0.01, size=(2,1), requires_grad=True)
b = torch.zeros(1, requires_grad=True)
~~~

在初始化参数之后，接下来更新这些参数，直到这些参数足够拟合数据，并且误差尽可能的小

由梯度下降法知，更新参数要参照损失函数，而每次更新都需要计算损失函数关于模型参数的梯度。 

这个梯度的计算用到上面写的自动求导

### 定义模型：

有了参数，确定模型的形式，那当然是线性模型

然后将输入特征和参数结合起来
$$
𝐲=𝐗𝐰+𝑏
$$
哈哈，很简单，但需要注意的是𝐗𝐰是向量，而偏置*b*是标量，怎么相加呢？

广播机制，相加时，将b扩展为与𝐗𝐰形状相同的列向量，然后直接相加

~~~py
def linreg(X, w, b):  #以函数的形式定义模型,计算的时候直接调用函数
    """线性回归模型"""
    return torch.matmul(X, w) + b #𝐲=𝐗𝐰+𝑏
~~~

### 定义损失函数：

损失函数是用最小二乘法得到的
$$
\frac{1}{2}(𝑦̂−𝑦)^2
$$
实现时，需要将真实值y的形状转换为和预测值y_hat的形状相同，那为什么重新塑形保证形状相同？

因为虽然真实值和预测值的元素个数相同，但真实值或预测值一个可能是行向量，一个可能是列向量

~~~py
def squared_loss(y_hat, y):  #@save
    """均方损失"""
    return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2 #1/2(𝑦̂−𝑦)^2
					#重新塑形,保证与预测值形状相同
    #这里没有做均值,只是将全部的加起来了
~~~

### 定义优化算法：

利用梯度下降对参数进行优化

梯度下降采用小批量随机梯度下降，该变体方法又快又稳

~~~py
#params参数(list),包含了w,b
#lr学习率,batch_size批量大小
def sgd(params, lr, batch_size):    
    """小批量随机梯度下降"""
    with torch.no_grad(): #表示该函数不要计算梯度,只用梯度进行运算
        for param in params: #遍历参数列表,对列表的每个参数进行更新
            param -= lr * param.grad / batch_size #更新参数,可概括为 新w = 旧w - 步长
            		#除以批量是因为损失函数没有做均值,这里补上,在损失函数中除效果也是一样的
            param.grad.zero_()#更新之后会选取下一组批量,梯度会重新计算,所以将该批量下的梯度清0
~~~

### 训练：

~~~py
lr = 0.03 #设学习率为0.03
num_epochs = 3 #数据集扫描3次

net = linreg #net为定义的线性模型𝐲=𝐗𝐰+𝑏
loss = squared_loss #损失函数,均方损失
#以上两条都是将对应模型换名字,这样的好处比如模型发生改变了,直接更改net的赋值即可

for epoch in range(num_epochs): #扫描数据集3次
    for X, y in data_iter(batch_size, features, labels): 
        #每次拿出批量大小的X,y进行迭代,直至遍历完整个数据集
        
        l = loss(net(X, w, b), y)  #预测值与真实值做损失
        
        #因为l形状是(batch_size,1)，而不是一个标量。
        #向量如何求梯度,要么转换为标量,要么设置gradient参数
        #将l中的所有元素被加到一起,进行降维
        #并以此计算关于[w,b]的梯度
        l.sum().backward() #等价于l.backward(torch.ones(len(l)))
        
        sgd([w, b], lr, batch_size)  #使用参数的梯度更新参数
        #batch_size不是比较正确,因为最后取的数量可能不满足批量大小
        #但这里选择批量为10正好可以被1000整除所以不用担心这一点
        
    with torch.no_grad(): #扫描一次后对迭代参数进行评估,此时不需要计算梯度
        train_l = loss(net(features, w, b), labels) 
        #将新迭代的参数与特征数据集进行计算得到新的预测值,与标签数据集做损失
        print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')
        #得迭代次数和损失均值,均值越小说明模型拟合越精确
~~~

因为是人工创建的数据集，我们知道正确的权重和偏置，即𝐰=[2,−3.4]^⊤^，𝑏=4.2

~~~py
print(f'w的估计误差: {true_w - w.reshape(true_w.shape)}')
print(f'b的估计误差: {true_b - b}')
~~~

所以可以做一下差值，看看误差是多少



## 线性回归的简洁实现：

上面的线性回归是手动实现的，从数据集生成到模型定义，一步一步手动实现

这对学习能够加深理解，但运行效率或许很低。

随着深度学习的发展已经有很多实现优化好的，现成的可以拿来用

接下来就来学习通过使用深度学习框架来简洁地实现线性回归😸

简洁实现就是使用pytorch中nn的模组(nn神经网络的缩写)中提供的数据预处理模块使实现更加简单

### 生成数据集：

~~~py
import numpy as np
import torch
from torch.utils import data #其中包含一些处理数据的模块
from d2l import torch as d2l

#真实权重
true_w = torch.tensor([2, -3.4])
true_b = 4.2 

#人工数据合成函数,这个函数在上节已经实现直接拿来用啦
features, labels = d2l.synthetic_data(true_w, true_b, 1000)
~~~

### 读取数据集：

~~~py
def load_array(data_arrays, batch_size, is_train=True):  #@save
    """构造一个PyTorch数据迭代器"""
    dataset = data.TensorDataset(*data_arrays)
    return data.DataLoader(dataset, batch_size, shuffle=is_train)


batch_size = 10
data_iter = load_array((features, labels), batch_size)
~~~

#### data.TensorDataset()

百度了一会子也没百度出个所以然，理解为data包中的一个将两个张量对应的打包函数

举例子试试怎么用

~~~py
import torch
from torch.utils import data

features = torch.tensor([[1,2],[3,4],[5,6]])
labels = torch.tensor([1,2,3])
dataset = data.TensorDataset(*(features,labels))
#弹幕好哥哥提醒,这个星号是元组拆包符号,将列表元素分别当作参数传入进去

for i in dataset:
    print(i)
    
(tensor([1, 2]), tensor(1))
(tensor([3, 4]), tensor(0))
(tensor([5, 6]), tensor(1))
~~~

两个张量要这样进行打包的话，这两个张量的第一维度必须相同，比如features为2x2，labels 为2

这两个张量的轴0是相同的

#### data.DataLoader()

数据加载器，结合了数据集和取样器，可以根据参数设置大小抛出一定数量的数据

书上出现的几个参数：

- **dataset** -- 相当于抛出数据的数据库
- **batch_size** -- 抛出的数据数量
- **shuffle** -- 抛出是否随机

~~~py
dataset = data.TensorDataset(*(features,labels))

next(iter(data.DataLoader(dataset,1,shuffle = True))
#每次随机抛出一个,直至把所有的数据都抛出
~~~

#### iter()和next()

list、tuple、dict、set还有现在使用的tensor，都是可迭代的对象

使用yield返回的生成器也可以迭代

调用iter()函数可获得这些对象的迭代器

对获取到的迭代器不断调用next()函数来获取下⼀条数据

~~~py
x = iter(torch.tensor([[1,2],[3,4],[5,6]]))

next(x)
tensor([1, 2])
next(x)
tensor([3, 4])
next(x)
tensor([5, 6])
next(x,-1) 
#可选，用于设置在没有下一个元素时返回该默认值,如果不设置,又没有下一个元素则会触发StopIteration异常
-1
~~~

