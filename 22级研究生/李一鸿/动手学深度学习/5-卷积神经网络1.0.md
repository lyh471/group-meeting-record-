# 卷积神经网络

## 卷积和卷积层

卷积神经网络（convolutional neural network，CNN）是一类强大的、为处理图像数据而设计的神经网络。在学习卷积神经网络前，先明白几个问题什么是卷积？什么是卷积层？

先看一个问题，我们现在的图片动则1M像素是常有的事，假设我们需要对这1M像素进行图片识别，如果使用全连接层，设该全连接层可将1M像素降维到1000个输出单元，那么权重矩阵的元素数目仍为10^6^ *1000=10亿

十亿个参数去用来拟合一张图片显然是不科学的，但现在的机器学习却能够很好的进行图片识别，这是因为图像中本就拥有丰富的结构，而这些结构可以被人类和机器学习模型使用。 

举个在王老师👑🪵视频上看到的例子😸

<img src="C:\Users\lyh471\AppData\Roaming\Typora\typora-user-images\image-20220624114226595.png" alt="image-20220624114226595" style="zoom:50%;" />

我们要识别图中这 × ，但重点不是识别规规整整的情况，而是如下图所示这种不规则的情况也要识别出来

<img src="C:\Users\lyh471\AppData\Roaming\Typora\typora-user-images\image-20220624114525975.png" alt="image-20220624114525975" style="zoom:88%;" />

这种情况我们是一眼就能看出来的，但对于计算机看到的只是像素点，而这两张图片的像素点是不匹配的

但是如果只看局部的话

<img src="C:\Users\lyh471\AppData\Roaming\Typora\typora-user-images\image-20220624115024156.png" alt="image-20220624115024156" style="zoom:25%;" />

局部是有相同情况的，所以卷积神经网络识别图像的第一步就是根据图像中普适的局部特征给挑出来，将这些局部特征交给神经网络，由神经网络进行打分判断，概括的说==卷积神经网络就是机器学习利用自然图像中一些已知结构的创造性方法。==

### 识别图像的原则：

”沃尔多在哪里”是一个儿童读物中的游戏： 在这个游戏中包含了许多充斥着活动的混乱场景，而沃尔多通常潜伏在一些不太可能的位置，读者的目标就是找出他。 

尽管沃尔多的装扮很有特点，但是在眼花缭乱的场景中找到他也如大海捞针。 

然而沃尔多的样子并不取决于他潜藏的地方，就像从一张图片中找到某个物体，猪🐷不会再天上飞的， 但如果一只猪出现在图片顶部，我们还是应该认出它

- 这就是**平移不变性**，不管检测对象出现在图像中的哪个位置，不会因对象的位置，而认为对象发生了改变。神经网络的前面几层应该对相同的图像区域具有相似的反应，即为“平移不变性”。

因此我们可以使用一个“沃尔多检测器”扫描图像。 该检测器将图像分割成多个区域，并为每个区域包含沃尔多的可能性打分。

- 将图片划分成多个区域，就利于了识别图像的**局部性**，神经网络的前面几层应该只探索输入图像中的局部区域，而不过度在意图像中相隔较远区域的关系，这就是“局部性”原则。

如果只是在图片中寻找在局部躲藏的沃尔多，那么选择分数最高的区域我们就能找到他。但如果我们如果用来识别一只猫猫🐱的话，我们也可以将图片划分多个区域，然后对所有区域使用猫猫👂“检测器”、猫猫尾巴“检测器”.......等等，最后聚合这些局部特征，并根据局部区域分布的位置进行组合，从而对整个图像级别进行预测。

利用这两个性质，可以帮助我们设计适合于计算机视觉的神经网络架构

### 卷积：

卷积神经网络的最主要的用途就是识别图中的内容，之所以为何称为卷积神经网络，就是在识别图像前对图片进行卷积操作。

我们知道将一张1M像素的图片展平进行输入是不可能的，但根据识别图像的性质，我们可以将图片划分一个一个区域，然后对于每个区域通过一个“过滤器”的东西将其特征给挑出来，然后把这些局部特征交给神经网络，由神经网络去判断。这样就不必将整个图片的所有像素进行输入，而这个过滤器就是**卷积核**

卷积操作就是对图片的像素点以及它周围的像素进行主动的试探和选择，通过卷积核将有用的特征保留下来

可以用下图形象的解释：

<img src="C:\Users\lyh471\AppData\Roaming\Typora\typora-user-images\image-20220624155628756.png" alt="image-20220624155628756" style="zoom:33%;" />

最底层蓝色的是我们需要识别的图片张量，蓝色阴影区域是我们的一个3×3大小的卷积核张量，在这个区域部分输入张量与卷积核张量进行按元素相乘，得到的张量再求和得到一个单一的标量值，由此我们得出了这一位置的输出张量值，即为绿色部分阴影区域。我们可以通过二维互相关运算，使卷积核窗口从输入张量的左上角开始，从左到右、从上到下滑动，从而遍历整张图片

==卷积核的大小就是相当于将图片划分区域的大小，局部输入与卷积核进行运算得到的输出相当于对特征的提取==

### 卷积层：

所以我们由卷积操作可以引出卷积层，我们知道全连接层的弊端，所以对于一张图片的识别，我们不会在对它进行展平操作换成一维向量进行输入，我们就以图片本身的结构划分若干个区域，这些若干个区域与某个神经元相连。这样连接得到的层次，我们称为卷积层。这个神经元就是卷积核，区域与神经元相连的参数称为核权重。

卷积核的核权重是共享的，即无论对图片的哪个区域连接，其参数都是不变的，这也就满足了识别图片的**平移不变性**。同样我们可以根据卷积核的大小，确定图片划分局部区域的大小，这体现了识别图像的**局部性**，而当卷积核的大小与图片大小一一对应时，此时的卷积层就相当于一个“全连接层”。而由于无论是卷积层还是全连接层，都是输入张量与权重张量做点积的，两者的相互转换是可能的，所以也可以说卷积层是特殊的全连接层。

然后将划分的所有区域从左上角开始，从左到右、从上到下滑动，与卷积核按元素相乘，得到的张量再求和得到一个单一的标量值，然后再加上偏置，这就是卷积层的前向传播运算——*二维互相关运算*

⚠️从上面图形的映射我们也可以看出，输出（上方绿色的层）大小略小于输入（下方蓝色的层），这是因为卷积核的宽度和高度大于1， 而卷积核只与图像中每个大小完全适合的位置进行互相关运算。 所以，输出大小等于输入大小𝑛~ℎ~×𝑛~𝑤~减去卷积核大小𝑘~ℎ~×𝑘~𝑤~即输出张量的形状为

<img src="C:\Users\lyh471\AppData\Roaming\Typora\typora-user-images\image-20220624163237801.png" alt="image-20220624163237801" style="zoom: 50%;" />

（n~h~、n~w~是输入张量的高度和宽度，k~h~、k~w~是卷积核张量的高度核宽度）

所有我们需要足够的空间在图像上“移动”卷积核。这可以通过在图像边界周围填充零的方法来保证有足够的空间移动卷积核，从而保持输出大小不变。 

- 卷积层将输入与核矩阵进行交叉相关运算，加上偏移后得到输出
- 核矩阵的权重以及偏移是可学习训练的参数
- 核矩阵的大小是超参数（控制图片划分的局部性）

## 卷积层的实现

### 互相关运算：

在实现卷积层之前，首先定义卷积层的前向传播，对于通道为1的黑白像素图片计算为二维相关运算

~~~py
import torch
from torch import nn
from d2l import torch as d2l

#定义二维互相关运算
def corr2d(X, K):  #X输入,K为卷积核
    """计算二维互相关运算"""
    
    h, w = K.shape #核的行数与列数
    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))
    #根据输入张量的形状与核的形状计算出输出张量的形状
    
    for i in range(Y.shape[0]):
        for j in range(Y.shape[1]):
            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()
    #从左上角开始,从左到右、从上到下滑动.与卷积核按元素相乘,得到的张量再求和得到一个单一的标量值
            
    return Y #返回计算后的张量
~~~

<img src="C:\Users\lyh471\AppData\Roaming\Typora\typora-user-images\image-20220624164926012.png" alt="image-20220624164926012" style="zoom: 50%;" />

以上图为例验证二维互相运算

~~~py
X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])
K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])
corr2d(X, K)

tensor([[19., 25.],
        [37., 43.]])
~~~

### 自定义卷积层：

卷积层对输入和卷积核权重进行互相关运算，并在添加标量偏置之后产生输出。 所以，卷积层中的两个被训练的参数是卷积核权重和标量偏置，初始化时同样要对权重核偏置进行声明。

卷积层的前向传播就是刚刚上面定义的二维互相关运算

~~~py
class Conv2D(nn.Module): #二维卷积层
    def __init__(self, kernel_size): #kernel_size是核的大小,超参数,可以是一个元组来确定核的形状
        super().__init__()
        self.weight = nn.Parameter(torch.rand(kernel_size)) 
        self.bias = nn.Parameter(torch.zeros(1))
        #权重和偏置为nn.Paramete()实例对象,说明可以计算梯度可以训练

    def forward(self, x):
        return corr2d(x, self.weight) + self.bias
    #卷积层的前向传播,说明与神经元如何连接
~~~

### 应用：

通过找到像素变化的位置，来(**检测图像中不同颜色的边缘**)。 首先，我们构造一个6×8像素的黑白图像。

中间四列为黑色（0），其余像素为白色（1）。

~~~py
X = torch.ones((6, 8))
X[:, 2:6] = 0

K = torch.tensor([[1.0, -1.0]]) #已知的卷积核

Y = corr2d(X, K)
Y

tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],
        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],
        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],
        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],
        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],
        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])
~~~

输出Y中的1代表从白色到黑色的边缘，-1代表从黑色到白色的边缘，其他情况的输出为0。很明显，输入的张量与卷积核进行运算，把我们想要的特征提取出来了！🦝

⚠️但是该卷积核K只可以检测垂直边缘，无法检测水平边缘。

这是我们已知卷积核时得到的结果，但当我们事先不知道卷积核的权重数值为[[1.0, -1.0]]时，卷积核的值能否被训练出来呢？

下面简单的进行训练学习一下，看看能不能迭代出符合要求的卷积核权重

~~~py
conv2d = nn.Conv2d(1,1, kernel_size=(1, 2), bias=False)
#这是用深度学习框架定义的卷积层,前面两个1分别表示输入的通道核输出的通道,现在暂时忽略掉
#该卷积层它具有1个输出通道和形状为（1，2）的卷积核
#怎么又知道卷积核的大小了？这是作弊！但是我们重点还是关心是否能训练出核权重的数值,至于核的大小是超参数不参与训练

#这个二维卷积层使用四维输入和输出格式（批量大小、通道、高度、宽度），
#其中批量大小和通道数都为1
X = X.reshape((1, 1, 6, 8)) #输入张量的形状
Y = Y.reshape((1, 1, 6, 7)) #输出张量的形状
lr = 3e-2  #学习率

#手写训练逻辑,就一个批量大小的简单的梯度下降,
for i in range(10):
    Y_hat = conv2d(X) #预测值
    l = (Y_hat - Y) ** 2 #均方损失
    conv2d.zero_grad() #梯度清零为下次梯度计算做准备
    l.sum().backward() #计算损失函数梯度
    # 迭代卷积核
    conv2d.weight.data[:] -= lr * conv2d.weight.grad
    if (i + 1) % 2 == 0: #显示训练后的损失
        print(f'epoch {i+1}, loss {l.sum():.3f}')
~~~

在10次迭代之后，误差已经降到足够低。现在我们来看看我们学的卷积核的权重张量

~~~py
conv2d.weight.data.reshape((1, 2))

tensor([[ 0.9879, -0.9993]])
~~~

该数值十分接近我们之前定义的卷积核K。说明训练学习成功👻