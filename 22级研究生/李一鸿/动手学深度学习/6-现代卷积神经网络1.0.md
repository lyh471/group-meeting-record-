# 现代卷积神经网络

## AlexNet（深度卷积神经网络）

**AlexNet**本质上是一个更大更深的LeNet，在架构上并没有本质的区别

主要改进就算在LeNet的基础上增加了：

- 丢弃法（dropout）
- 将激活函数Sigmoid改成了ReLu
- 将平均池化层AvgPool替换为最大池化层MaxPool

丢弃法可以看作对模型的控制，模型复杂程度太高了使用丢弃法降低模型的复杂度；而激活函数ReLu可以使数值更稳定防止梯度爆炸或消失，因为ReLu在0点附近导数更加好一点可以支持更深的模型；最大池化层可以保证输出比较大，从而使梯度比较大，使得训练相对容易一点（都是前面的知识🙉）

当然它不仅仅是让网络变得更大更深，该网络设计的原则更多的是观念上发生的改变，LeNet（大小写混打好麻烦，以后统一小写😾）仍可以理解为机器学习上的模型，但对于alexnet因为网络层数增大了几十倍，使得量变产生了质变，对整个**计算机视觉方法论的观念**改变了（箭头画的好歪=-=）

<img src="C:\Users\lyh471\AppData\Roaming\Typora\typora-user-images\image-20220701173711201.png" alt="image-20220701173711201" style="zoom:50%;" />

最初研究计算机视觉识别时最重要的就是如何==人工提取特征==，得到特征后我们利用机器学习模型进行识别，但是深度学习神经网络通过==卷积层来学习特征==，然后经过softmax回归进行归类，即特征提取模型和分类器是一起训练的。而不是像机器学习需要视觉专家独立人工提取专家们希望得到的特征，然后使用机器模型进行识别特征。

深度学习神经网络的好处是：

- 构造卷积层相对简单，不需要了解太多计算机视觉专业的知识来人工提取特征
- 特征学习模型和分类模型是在一起训练，模型角度来讲是整体的，这样更加高效准确

所以利用深度学习神经网络我们不需要人工提取特征，而是利用原始图片直接端到端得到我们最终想要的结果

### 架构：

架构就是更大的更深的lenet，alexnet的输入图片是3×224×224大小的图像（RGB三通道彩色图像）

具体架构看下图吧，我就不一层一层的再解释了，在lenet架构中那种解释说的很详细，看着alexnet的架构举一反三就是了

<img src="C:\Users\lyh471\AppData\Roaming\Typora\typora-user-images\image-20220701173928634.png" alt="image-20220701173928634" style="zoom: 50%;" />

⚠️注意，该图片架构提供了一个稍微精简版本的AlexNet，去除了当年设计比赛时出现的需要两个小型GPU同时运算的设计特点。

相比lenet有很明显的变化，入通道数，比如第一个卷积层的通道数为96，得到通道数为96的输出，第一层就尝试识别更大的特征，并且第一层的步幅为4，如果步幅不大一些在当时年代设计网络时GPU还没那么好用，会占用很大内存和计算会很慢。所以刚开始步幅不设置很大的话，后面的计算会特别难

第二层为池化层，使用的最大池化层而不是平均池化层。并且使用的3×3，3×3与2×2的区别在于，2×2允许一个像素偏移一点点，而3×3池化层像素往左移一下往右移一下都ok（移动两点点？），步幅为2将高宽减半

哎呀，我又开始一层一层对比详解起来了，后面就不看啦~总之架构就是这样的架构！比lenet多了很多东西😸

🦝这些网络到底什么神仙想出来的....最关键的是还能用....经验+理论？或许吧，希望将来我也能做出这样的网络名垂青史

当然这是一个架构，在这个架构上还要很多细节的东西，比如：

- 激活函数从sigmoid变到了ReLu避免了梯度消失
- 隐藏层全连接层后加入了丢弃层
- 数据增强

把前面的东西，又强调了一遍.....但数据增强还是要说道说道，比如使用最大池化层强度数据，或者对样本数据图片随机截取局部特征来训练，在图片上增加噪音，或者进行亮度调节，色温增强等改变图片的多样性。因为卷积对位置是比较敏感的，光照之类的都敏感。如何脱敏就是在输入图片中增加大量变种，因为神经网络非常擅长==记住所有数据（过拟合）==，那么经过数据增强后，记住数据的能力就变低了

**之后会有专门的课来将数据增强，因为对计算机视觉来讲太重要了**

总之：

- alexnet是更大更深的lenet，10×参数个数，260×计算复杂度
- 在lenet基础上引入了丢弃法，ReLu，最大池化层，数据增强
- 该网络赢下了2012**imageNet**竞赛后，标志着新的神经网络热潮开始

### 实现：

实现也没有什么好说的，学习这些网络不思考如何构建的话很好学，注意一些其中的细节然后按照架构模型实例化一个顺序容器对象在上面一点一点的加结构所需的层就能把网络做出来了

~~~py
import torch
from torch import nn
from d2l import torch as d2l

#对着参数架构把对于的层放进来

net = nn.Sequential(
   
    nn.Conv2d(1, 96, kernel_size=11, stride=4, padding=1), nn.ReLU(),
    #使用的是fashion_mnist数据集,如果使用的imagenet中数据集通道数为3
    #输出通道的数为96,远大于LeNet
    #使用一个11×11卷积核
    #步幅为4,减少输出的高度和宽度
    nn.MaxPool2d(kernel_size=3, stride=2),
   
    nn.Conv2d(96, 256, kernel_size=5, padding=2), nn.ReLU(),
    #减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致,且增大输出通道数
    nn.MaxPool2d(kernel_size=3, stride=2),

    nn.Conv2d(256, 384, kernel_size=3, padding=1), nn.ReLU(),
    nn.Conv2d(384, 384, kernel_size=3, padding=1), nn.ReLU(),
    nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(),
    #使用三个连续的卷积层和较小的卷积窗口
    #除了最后的卷积层,输出通道的数量进一步增加。
    nn.MaxPool2d(kernel_size=3, stride=2),
    
    nn.Flatten(),
    nn.Linear(6400, 4096), nn.ReLU(),
    nn.Dropout(p=0.5),
    nn.Linear(4096, 4096), nn.ReLU(),
    nn.Dropout(p=0.5),
    #全连接层的输出数量是LeNet中的好几倍,使用dropout层来减轻过拟合

    nn.Linear(4096, 10)
    #最后是输出层,由于使用Fashion-MNIST,所以用类别数为10,而非论文中的1000
	)
~~~

### 训练：

为了演示网络使用的Fashion-MNIST10类小数据集.....谢谢太谢谢了，**但是**用cpu跑还是太勉强了，据弹幕好哥哥说跑了20分钟还没跑出来，所以我可不当☂️♟️在我的电脑上本地去跑。我就不训练了，以后有机会再说吧！🐻